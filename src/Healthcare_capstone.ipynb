{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Business Understanding \n",
    "\n",
    "CMS rates hospitals in the US on a scale of 1-5 with the objective to make it easier for patients and consumers to compare the quality of hospitals.\n",
    "The ratings directly influence the choice of the hospital made by consumers and may have a significant impact on the revenue earned by hospitals.\n",
    "Thus, it is extremely important for hospitals to understand the methodology used by CMS for calculating the ratings so that they can work on\n",
    "improving the factors that influence them.\n",
    " \n",
    "This project is focused on developing an approach to calculate hospital ratings and using it to identify areas of improvement for\n",
    "certain hospitals. It will also require a thorough understanding of the rating system developed by CMS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Business Problem \n",
    "\n",
    "The aim of analysis is to understand the methodology used by CMS for calculating the ratings and identify\n",
    "the factors influencing the ratings for hospitals, so that they can work on improving the factors that influence them.\n",
    "Recommend ways to improve the rating for Evanston Hospital to improve their current star rating of 3/5*\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Understanding #\n",
    "\n",
    "The original source of data is `Hospital_Revised_FlatFiles_20161110`\n",
    "  CSV Files\n",
    "1.\tReadmissions and Deaths - Hospital.csv\t                                                readmission.csv\n",
    "2.\tReadmissions and Deaths - Hospital.csv +   Complications - Hospital.csv\t                mortality.csv\n",
    "3.\tHealthcare Associated Infections - Hospital.csv +   Complications - Hospital.csv\t      safety.csv\n",
    "4.\tHCAHPS - Hospital.csv\t                                                                  experience.csv\n",
    "5.\tOutpatient Imaging Efficiency - Hopital.csv\t                                            medical.csv\n",
    "6.\tTimely and Effective Care - Hospital.csv\t                                              timeliness.csv\n",
    "7.\tTimely and Effective Care - Hospital.csv\t                                              effectiveness.csv\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis \n",
    "\n",
    "- Perform the Univariate analysis for all the groups.\n",
    "- Perform Bi-variate analysis for all the groups.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Modelling \n",
    "\n",
    " Part 1 - Supervised Learning-Based Rating\n",
    " Part 2 - Factor analysis and Clustering-Based Rating (Unsupervised)\n",
    " Part 3 - Provider analysis - Recommendations for Hospitals\n",
    "\n",
    "Let us load the data and create the groups as above:\n",
    "Copied the required raw files to the Groups location.\n",
    "1. \"Readmissions and Deaths - Hospital.csv\"\n",
    "2. \"Complications - Hospital.csv\"\n",
    "3. \"Healthcare Associated Infections - Hospital.csv\"\n",
    "4. \"HCAHPS - Hospital.csv\"\n",
    "5. \"Outpatient Imaging Efficiency - Hospital.csv\"\n",
    "6. \"Timely and Effective Care - Hospital.csv\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Data Prepartion, cleaning and Supervised Modelling \n",
    "Data set contains 58 excel files, 2 PDF files out of this for this assignment we require 6 files & it has suffix as \"_Hospital\"\n",
    "\n",
    "Load the files into dataframes:\n",
    "1. Load the data - replace Not Available, Not Applicable with NA  (Suffix _Raw dataframes )\n",
    "2. Split xxxx_rawdata frames into 2 data frames [xxxx_hosp, xxxx_meas)\n",
    "3. Rename columns - Standardize names across\n",
    "4. Reorder columns to match all files\n",
    "5. Standardize the measures- some measures with positive zscores and some measures with negative zscores.\n",
    "6. Impute the outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Libraries to be used\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.chdir(\"/Users/eklavya/projects/education/formalEducation/DataScience/DataScienceAssignments/HealthCare/Capstone/src/\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from random import sample\n",
    "from numpy.random import uniform\n",
    "from math import isnan\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Utility functions "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def print_ln():\n",
    "    print('-' * 80, '\\n')\n",
    "\n",
    "\n",
    "# Function to create a subset of the dataframe\n",
    "def subset(dataframe, col_name, col_names_list):\n",
    "    return dataframe.loc[dataframe[col_name].isin(col_names_list)]\n",
    "\n",
    "# Converts the datatype of a specific column and returns the new dataframe\n",
    "def func_numeric(df, col_name):\n",
    "    df[col_name] = df[col_name].astype(float)\n",
    "    return df\n",
    "\n",
    "# Renames a column in the dataframe by appending `_score`.\n",
    "def func_rename(df):\n",
    "    old_col_names = df.columns.to_list()\n",
    "    new_col_names = []\n",
    "    for a_col_name in old_col_names:\n",
    "        col_name = a_col_name + \"_score\"\n",
    "        new_col_names.append(col_name)\n",
    "\n",
    "    name_pairs = dict(zip(old_col_names, new_col_names))\n",
    "    df = df.rename(columns=name_pairs)\n",
    "    return df\n",
    "\n",
    "# Function to compute the negative zscore value for the dataframe\n",
    "\n",
    "def negative_zscore(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        df[col] = - (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
    "    return df\n",
    "\n",
    "# Function to compute the positive zscore value for the dataframe\n",
    "def positive_zscore(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        df[col] = (df[col] - df[col].mean())/df[col].std(ddof=0)\n",
    "    return df\n",
    "\n",
    "# Function to compute the valid subset of a dataframe i.e. reduces outliers via IQR method\n",
    "def subset_by_iqr(df, column, whisker_width=0):\n",
    "    # Calculate Q1, Q2 and IQR\n",
    "    q1 = df[column].quantile(0.00125)\n",
    "    q3 = df[column].quantile(0.99875)\n",
    "    iqr = q3 - q1\n",
    "    # Apply filter with respect to IQR, including optional whiskers\n",
    "    filter = (df[column] >= q1 - whisker_width*iqr) & (df[column] <= q3 + whisker_width*iqr)\n",
    "    return df.loc[filter][column]\n",
    "\n",
    "\n",
    "# Driver function for `subset_by_iqr` which treats the outliers in a dataframe\n",
    "def treat_outliers(dataframe):\n",
    "    df = dataframe.copy()\n",
    "    cols = list(df.columns)\n",
    "    for col in cols:\n",
    "        df[col] = subset_by_iqr(df, col)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "# Computes the group score of a dataframe after cleaning and doing PCA on the group of measures\n",
    "def function_group_score(numeric_df, score_name):\n",
    "    # CMS recommends atleast 3 non-null measures per group\n",
    "    df = numeric_df.dropna(thresh= 3)\n",
    "    imputed_df = df.apply(lambda x: x.fillna(x.median()), axis=0)\n",
    "    pca = IncrementalPCA()\n",
    "    df_pca = pca.fit_transform(imputed_df)\n",
    "    df_pca = pd.DataFrame(df_pca, columns= df.columns)\n",
    "    df_pca.index = df.index\n",
    "    df_with_weight = df_pca.mean(axis=1)\n",
    "    df_scores = pd.DataFrame({score_name : df_with_weight})\n",
    "    return df_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Readmission - Load \"Readmissions and Deaths - Hospital.csv\" file into read_raw"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Readmissions and deaths \n",
    "\n",
    "read_rawdata = pd.read_csv(\"Readmissions and Deaths - Hospital.csv\",\n",
    "                           encoding=\"ISO-8859-1\",\n",
    "                           na_values=[\"Not Available\", \"Not Applicable\"])\n",
    "\n",
    "## Declaring the list of important measures associated with this particular group\n",
    "read_meas_list =   [\"READM_30_AMI\", \"READM_30_CABG\", \"READM_30_COPD\", \"READM_30_HF\", \"READM_30_HIP_KNEE\", \"READM_30_HOSP_WIDE\", \"READM_30_PN\", \"READM_30_STK\"]\n",
    "\n",
    "read_hosp = read_rawdata.iloc[:,0:8]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "read_hosp = read_hosp.drop_duplicates(keep='first')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "read_meas = read_rawdata.iloc[: , [0,9,12]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Converting the datatype of Score to a float\n",
    "\n",
    "read_meas['Score'] = read_meas['Score'].astype(float)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
